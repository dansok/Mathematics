\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm, mathrsfs}
\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{0.8in}
\addtolength{\textheight}{0.8in}
\addtolength{\topmargin}{-.4in}
\newtheoremstyle{quest}{\topsep}{\topsep}{}{}{\bfseries}{}{ }{\thmname{#1}\thmnote{ #3}.}
\theoremstyle{quest}
\newtheorem*{definition}{Definition}
\newtheorem*{theorem}{Theorem}
\newtheorem*{question}{Question}
\newtheorem*{exercise}{Exercise}
\newtheorem*{challengeproblem}{Challenge Problem}
\newcommand{\name}{%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% put your name here, so we know who to give credit to %%
Dan Sokolsky
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\hw}{%%%%%%%%%%%%%%%%%%%%
%% and which homework assignment is it? %%%%%%%%%
%% put the correct number below              %%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
7
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-50pt}
\Huge \name
\\\vspace{20pt}
\huge Linear Algebra II\hfill Homework \hw}
\author{}
\date{}
\pagestyle{myheadings}
\markright{\name\hfill Homework \hw\qquad\hfill}

%% If you want to define a new command, you can do it like this:
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}

%% If you want to use a function like ''sin'' or ''cos'', you can do it like this
%% (we probably won't have much use for this)
% \DeclareMathOperator{\sin}{sin}   %% just an example (it's already defined)


\begin{document}
\maketitle

\begin{question}[1]
(a) Let $f(x) = ||x||$. Prove $f$ is continuous with respect to $d(x,y) = ||x-y||$.
\\(b) Let $f: \mathcal{L}(X, U) \rightarrow \mathbb{R}$ be defined by $f(A) = ||A||$. Prove $f$ is continuous with respect to $d(A, B) = ||A-B||$.
\\(c) Prove $f$ defined in $(a)$ is continuous with respect to $d(x,y) = \max_j |x_j - y_j|$.
\\(d) Prove $f$ defined in $(b)$ is continuous with respect to $d(A, B) = \max_{i,j} |A_{i,j}-B_{i,j}|$.
\end{question}
\begin{proof}
We prove the reverse triangle inequality using the standard triangle inequality for an arbitrary norm first -- $$||y|| = ||x + (y-x)|| \le ||x|| + ||y-x|| \iff ||y|| - ||x|| \le ||y-x|| = ||x-y||$$
Likewise, $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ||x|| - ||y|| \le ||x-y||$
\\Together, $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ |\ ||x|| - ||y||\ | \le ||x-y||\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (7.1)$
\\For the first two sections suffices to verify the standard triangle inequality applies, whence $(7.1)$ holds, and continuity follows.
\\$\textbf{(a)}\ ||x-y|| \le \epsilon \implies |f(x)-f(y)| = |\ ||x|| - ||y||\ | \le ||x-y|| \le \epsilon$.
\\$\textbf{(b)}$ By Theorem $(14)(ii)$ in chapter $7$, $||A + B|| \le ||A|| + ||B||$.
\\Thus, $||A-B|| \le \epsilon \implies |f(A)-f(B)| = |\ ||A||-||B||\ | \le ||A-B|| \le \epsilon$
\\$\textbf{(c)}$ Let $i$ be such that $|x_i - y_i| = \max_j |x_j - y_j|$. Let $k, \ell$ be such that $|x_k| = \max_j|x_j|,\\|y_\ell| = \max_j|y_j|$, and WLOG suppose $|x_k| \ge |y_\ell|$. Suppose $|x_i - y_i| = \max_j |x_j - y_j| \le \epsilon$. Then, $$|f(x)-f(y)| = |\ |x_k| - |y_\ell| \ | = |x_k| - |y_\ell| \le |x_k| - |y_k| =$$ $$|\ |x_k| - |y_k| \ | \le |x_k - y_k| \le |x_i - y_i| \le \epsilon$$
\\$\textbf{(d)}$ Let $p, q$ be such that $|A_{p, q} - B_{p, q}| = \max_{i, j} |A_{i, j} - B_{i, j}|$. Let $(k, \ell), (s, t)$ be such that $|A_{k, \ell}| = \max_{i, j}|A_{i,j}|, |B_{s, t}| = \max_{i, j}|B_{i, j}|$, and WLOG suppose $|A_{k, \ell}| \ge |B_{s, t}|$. Suppose $|A_{p, q} - B_{p, q}| = \max_{i, j} |A_{i, j} - B_{i, j}| \le \epsilon$. Then, $$|f(A)-f(B)| = |\ |A_{k, \ell}| - |B_{s, t}| \ | = |A_{k, \ell}| - |B_{s, t}| \le |A_{k, \ell}| - |B_{k, \ell}| =$$ $$|\ |A_{k, \ell}| - |B_{k, \ell}| \ | \le |A_{k, \ell} - B_{k, \ell}| \le |A_{p, q} - B_{p, q}| \le \epsilon$$
\end{proof}
\begin{question}[2]
(a) Let $A: X \rightarrow U$ be $A = \begin{pmatrix}
G & 0 \\
0 & H
\end{pmatrix}$. What can be said about $||A||$ in terms of $||G||, ||H||$?
\\(b) Let $A$ be $m \times n$. Let $B$ be $m \times (n+1)$ be $A$ with an appended column. Prove $||A|| \le ||B||$.
\\(c) Let $J_1, J_2$ be two Jordan blocks corresponding to the same eigenvalue. Show that if $J_2$ is a larger Jordan block then $J_1$, then $||J_1|| \le ||J_2||$.
\end{question}
\begin{proof}
$\textbf{(a)}$ Let $v$ be a unit vector. Suppose $G$ is $p \times k$ and $H$ is $q \times \ell$ where $p+q=n$. We write $v = \begin{pmatrix}
x \\
y
\end{pmatrix}$ where $x$ is $p \times 1$ and $y$ is $q \times 1$. Then,
$$||Av||^2 = \Big|\Big|\begin{pmatrix}
G & 0 \\
0 & H
\end{pmatrix}\begin{pmatrix}
x \\
y
\end{pmatrix}\Big|\Big|^2 = ||Gx||^2 + ||Hy||^2 \le |||G||^2||x||^2 + ||H||^2||y||^2$$
$$\le \max\{||G||^2, ||H||^2\} \cdot (||x||^2 + ||y||^2) = \max\{||G||^2, ||H||^2\} \cdot ||v||^2 = \max\{||G||^2, ||H||^2\}$$
$$\iff ||Av|| \le \max\{||G||, ||H||\} \iff ||A|| = \sup_{||w|| = 1}||Aw|| \le \max\{||G||, ||H||\}$$
\\$\mathbf{(b)}$ Let $x = \begin{pmatrix}
x_1 \\
\vdots \\
x_n
\end{pmatrix}$ be a unit vector. Let $x' = \begin{pmatrix}
x_1 \\
\vdots \\
x_n \\
0
\end{pmatrix}$. Then $||x'|| = ||x|| = 1$. Write $B = \begin{pmatrix}
A\ |\ \mathit{b}
\end{pmatrix}$, where $\mathit{b} = \begin{pmatrix}
\mathit{b}_1 \\
\vdots \\
\mathit{b}_m
\end{pmatrix}$. Denote by $A_i$ the $i^{th}$ row vector of $A$. Then,
$$||Ax||^2 = (A_1 \cdot x)^2 + \ldots + (A_m \cdot x)^2 = (A_1 \cdot x)^2 + \ldots + (A_m \cdot x)^2 + (\mathit{b} \cdot 0)^2$$
$$= ||Bx'||^2 \le ||B||^2||x'||^2 = ||B||^2 \iff ||Ax|| \le ||B||$$
Since $x$ is an arbitrary unit vector,
$$||A|| = \sup_{||v||=1}||Av|| \le ||B||$$
\\$\mathbf{(c)}$ Let $J_1$ be a Jordan block of size $m$, and $J_2$ a Jordan block of size $n$, with $m < n$. Let $\lambda$ be the eigenvalue of $J_1, J_2$. Let $x = \begin{pmatrix}
x_1 \\
\vdots \\
x_m
\end{pmatrix}$ be a unit vector. Let $x' = \begin{pmatrix}
x_1 \\
\vdots \\
x_m \\
0 \\
\vdots \\
0
\end{pmatrix}$ where the latter array of zeros in $x'$ is of size $n-m$. I.e., $x$ is $m \times 1$ and $x'$ is $n \times 1$, and $||x'|| = ||x|| = 1$. Then,
$$J_1 \cdot x = \begin{pmatrix}
\lambda x_1 + x_2 \\
\vdots \\
\lambda x_i + x_{i+1} \\
\vdots \\
\lambda x_m
\end{pmatrix}; \ \ \ J_2 \cdot x' = \begin{pmatrix}
\lambda x_1 + x_2 \\
\vdots \\
\lambda x_i + x_{i+1} \\
\vdots \\
\lambda x_m \\
0 \\
\vdots \\
0
\end{pmatrix} $$
Thus,
$$||J_1 \cdot x||^2 = ||J_2 \cdot x'||^2 \iff ||J_1 \cdot x|| = ||J_2 \cdot x'|| \le ||J_2|| \cdot ||x'|| = ||J_2||$$
Since $x$ is arbitrary,
$$||J_1|| = \sup_{||v|| = 1}||J_1 \cdot v|| \le ||J_2||$$
\end{proof}
\begin{question}[3]
Let $A: X \rightarrow U$. Let $Q: U \rightarrow U,\ P: X \rightarrow X$ be isometries.
\\(a) Prove $||A^*A|| = ||A||^2$
\\(b) Prove $||QA|| = ||A|| = ||AP||$
\\(c) Prove $A$ is invertible $\implies min_{||x||=1} ||Ax|| \ge ||A^{-1}||^{-1}$
\end{question}
\begin{proof}
$\mathbf{(a)}$ By Theorem $14,\ ||A^*A|| \le ||A^*|| \cdot ||A|| = ||A|| \cdot ||A|| = ||A||^2$.
Conversely, Let $x$ be a unit vector. Then 
$$||Ax||^2 = \langle Ax, Ax \rangle = \langle x, A^*Ax \rangle \le ||x|| \cdot ||A^*Ax|| = ||A^*Ax|| \le ||A^*A|| \cdot ||x|| = ||A^*A||$$
by the Schwarz inequality. Since $x$ is arbitrary,
$$||A||^2 = \sup_{||v||=1} ||Av||^2 \le ||A^*A||$$
Thus $||A^*A|| = ||A||^2$.
\\$\mathbf{(b)}$ By Theorem $12$, $||Q(Ax)|| = ||Ax||$, and $P$ (and $Q$) is invertible. Let $E = \{ x \in X : ||x|| = 1 \}$. Let $F = P^{-1}(E)$. Since $P$ is invertible, $P(F) = P(P^{-1}(E)) = E$. We claim $E = F-\ \ y \in F \implies Py \in E$, and $||y|| = ||Py|| = 1$ by definition of $E$. Thus $y \in E$. $x \in E \implies Px \in E$ since $||Px|| = ||x|| = 1$. Thus $x = P^{-1}(Px) \in F$. Therefore $E = F$ as claimed. Finally,
$$||QA|| = \sup_{x \in E} ||QAx|| = \sup_{x \in E} ||Ax|| = ||A||$$
and,
$$||A|| = \sup_{||x|| = 1}||Ax|| = \sup_{x \in E}||Ax|| = \sup_{y \in F}||APy|| = \sup_{||y|| = 1}||APy|| = ||AP||$$
\\$\mathbf{(c)}$ $$\dfrac{1}{\inf_{||x||=1} ||Ax||} = \sup_{||x||=1} \dfrac{1}{||Ax||} = \sup_{||x||=1} \dfrac{||x||}{||Ax||} = \sup_{||x||=1} \dfrac{||A^{-1}(Ax)||}{||Ax||} \le \sup_{x \in \mathbb{C}^n \setminus \{0\}} \dfrac{||A^{-1}(Ax)||}{||Ax||}$$
Since $A$ is nonsingular, $A(\mathbb{C}^n \setminus \{0\}) = \mathbb{C}^n \setminus \{0\}$ and therefore,
$$\sup_{x \in \mathbb{C}^n \setminus \{0\}} \dfrac{||A^{-1}(Ax)||}{||Ax||} = \sup_{y \in \mathbb{C}^n \setminus \{0\}} \dfrac{||A^{-1}y||}{||y||} = ||A^{-1}||$$
$$\iff \dfrac{1}{\inf_{||x||=1} ||Ax||} \le ||A^{-1}|| \iff \inf_{||x||=1} ||Ax|| \ge \dfrac{1}{||A^{-1}||}$$
\end{proof}
\begin{question}[4]
Let $A^* = A$.
\\(a) Show $(a,x),\ (b, y)$ distinct eigenpairs with $a \ne b$ $\implies $ $x$ and $y$ are orthogonal.
\\(b) $||A|| = max_j |a_j|$ over distinct eigenvalues $a_j$.
\end{question}
\begin{proof}$\mathbf{(a)}$ $$ax^*y = (ay^*x)^* = (y^*ax)^* = (y^*Ax)^* = x^*A^*y = x^*Ay = x^*by = bx^*y$$
$$\iff (a-b)x^*y = ax^*y - bx^*y = 0 \iff \langle x, y \rangle = x^*y = 0$$
since $a-b \ne 0$
\\$\mathbf{(b)}\ A = SJS^*$ where $J$ is diagonal and made up of the eigenvalues, and $S$ is unitary. In particular, $S,\ S^*$ are isometric. By question $(3)(b)$, $||A|| = ||SJS^*|| = ||J||$. Let $\lambda = max_j |a_j|$. Let $x$ be a \textbf{unit eigenvector} corresponding to $\lambda$. Then,
$$||J|| = \sup_{||y||=1}||Jy|| \ge ||Jx|| = \lambda \cdot ||x||  = \lambda$$
On the other hand, Since $J$ is a block diagonal matrix made up of $1 \times 1$ Jordan blocks made up of the eigenvalues, by problem $(2)(a)$,
$$||J|| \le \max_j|a_j| = \lambda$$
Therefore, $||A|| = ||J|| = \lambda = \max_j|a_j|$.
\end{proof}
\begin{question}[5]
Let $Y \subseteq X$ be a linear subspace. Given $x \in X, y \in Y$ solves $\min_{z \in Y} ||x-z||$, it follows that $\langle x-y, w \rangle = 0$ for all unit vectors $w \in Y$.
\end{question}
\begin{proof}
By equation $(4)$ on page $78$ and the corresponding discussion, $|| \cdot ||$ and $\langle \cdot, \cdot \rangle$ are geometric quantities, and are therefore independent of the choice of basis. Therefore, WLOG, we choose an orthonormal basis $\beta$ for X (one such basis can always be constructed from an arbitrary one by Gram-Schmidt). $\beta = \{y_1, \ldots, y_k, x_1, \ldots, x_{n-k}\}$, where $\{y_i\}_{i \le k}$ is a basis for $Y$. Thus by Theorem $8$, under the basis $\beta,\\ \min_{z \in Y} ||x-z|| = y = P_Y x$, the orthogonal projection of $x$ onto $Y$. Thus
\\$x = y + y^{\perp} \iff x-y = y^{\perp}$. Thus for any $w \in Y$ $\mathbf{-}$ in particular, for $||w|| = 1$ $\mathbf{-}$ $\langle x-y, w \rangle = \langle y^{\perp}, w \rangle = 0$.
\end{proof}

\end{document}
